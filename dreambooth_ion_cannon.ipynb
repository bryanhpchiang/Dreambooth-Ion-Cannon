{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d52a6063",
   "metadata": {},
   "source": [
    "# The Dreambooth Ion Cannon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a9718c",
   "metadata": {},
   "source": [
    "    The first thing I need to say is that this is not original work.\n",
    "    \n",
    "    It is based off of \"The Repo Formerly Known As Dreambooth\" by Joe Penna and his many extraordinarily talented collaborators, and further tweaks to the training process have been made by my friend Kane Wallmann. I am in awe of them, and owe them all a bottle of something from the top shelf.\n",
    "    \n",
    "    Dreambooth is a phenomenal piece of work, despite being described as 'walking through a jungle without a torch'.\n",
    "    \n",
    "    This variant of the repository is not an \"improvement\" per se - rather, it is a simplification of the process of\n",
    "    image generation by virtue of abstracting away details such as requiring you to interface with external sites, and\n",
    "    providing some prompts that I've found work quite well across the board.\n",
    "    \n",
    "    The cost to this abstraction is a significantly larger base repository, coming out at 4.8 gigabytes. Them's the breaks.\n",
    "    \n",
    "    There is still a level of technical know-how required, however you - the intended audience - are unlikely to be\n",
    "    reading this unless you've already followed part of the guide in the README for this repository fork, so you're\n",
    "    already most of the way there.\n",
    "    \n",
    "    Some provisos:\n",
    "        * I have bundled Stable Diffusion 1.4 in the repository containing this notebook. Please read the license \n",
    "          file `STABLE DIFFUSION LICENSE.md` in order to understand what you implicitly agree to by making use of this tech.\n",
    "          The long and short of it is that so long as you don't approach this tool with ill intent, you're fine.\n",
    "        * Despite Kane's adjustments enabling multi-subject training, this repo *at present* is designed to only accept \n",
    "          one subject at a time - that's what the prompts are expecting, so training multiple people is a waste. In future\n",
    "          iterations of this repository, I will introduce some branching logic allowing you to select how many people you\n",
    "          want to include in the generated images.\n",
    "          \n",
    "    I hope that that this inspires a little bit of wonder in you.\n",
    "    \n",
    "    /Laurence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f3a4bb",
   "metadata": {},
   "source": [
    "# Naming And Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e8e8a7",
   "metadata": {},
   "source": [
    "\\*\\*\\* This is the **only** cell you have to edit. \\*\\*\\* \n",
    "\n",
    "Before you opened this notebook per instructions from the repository, you should have uploaded 8-10 .png photographs of the person you are trying to generate images for into the directory `/training_samples/{class}` with filenames:\n",
    "\n",
    "* `name class_001.png`\n",
    "* `name class_001.png`\n",
    "* ...\n",
    "* `name class_00n.png`\n",
    "\n",
    "If you haven't done this, go back to the README of this repository (scroll down from the link you were given) and give it a go.\n",
    "\n",
    "Your choices for class are `man`, `woman` or `person`, whereas name is dealers choice, but do keep it as a single word (i.e. no spaces).\n",
    "\n",
    "**For example**, if you're trying to train on Princess Diana, your files would be called `princessdiana woman_001.png` et cetera.\n",
    "\n",
    "The spacing and underscores are important here, so please double-check.\n",
    "\n",
    "----\n",
    "\n",
    "In the cell below, edit the variables to reflect the `name` and `class` you have chosen. _Again_, please check for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e2bb93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_name = \"chrissy\"\n",
    "target_class = \"woman\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e4526a",
   "metadata": {},
   "source": [
    "# Now click *Cell > Run All Below* from the menu bar above.\n",
    "\n",
    "## Go away for 90 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07028870",
   "metadata": {},
   "source": [
    "# Build Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e1bc458-091b-42f4-a125-c3f0df20f29d",
   "metadata": {
    "id": "9e1bc458-091b-42f4-a125-c3f0df20f29d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: omegaconf in /home/bryan/venv/gpu/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from omegaconf) (6.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/bryan/venv/gpu/lib/python3.10/site-packages (from omegaconf) (4.9.3)\n",
      "Requirement already satisfied: einops in /home/bryan/venv/gpu/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: pytorch-lightning==1.6.5 in /home/bryan/venv/gpu/lib/python3.10/site-packages (1.6.5)\n",
      "Requirement already satisfied: torchmetrics>=0.4.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from pytorch-lightning==1.6.5) (0.6.0)\n",
      "Requirement already satisfied: torch>=1.8.* in /home/bryan/venv/gpu/lib/python3.10/site-packages (from pytorch-lightning==1.6.5) (1.13.0.dev20221005+cu117)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from pytorch-lightning==1.6.5) (2.10.1)\n",
      "Requirement already satisfied: pyDeprecate>=0.3.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from pytorch-lightning==1.6.5) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from pytorch-lightning==1.6.5) (4.64.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from pytorch-lightning==1.6.5) (21.3)\n",
      "Requirement already satisfied: protobuf<=3.20.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from pytorch-lightning==1.6.5) (3.19.6)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from pytorch-lightning==1.6.5) (1.23.3)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from pytorch-lightning==1.6.5) (2022.8.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from pytorch-lightning==1.6.5) (4.3.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from pytorch-lightning==1.6.5) (6.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (3.8.3)\n",
      "Requirement already satisfied: requests in /home/bryan/venv/gpu/lib/python3.10/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from packaging>=17.0->pytorch-lightning==1.6.5) (3.0.9)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.49.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (3.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (59.5.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.2.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (2.2.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.8.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (1.8.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (22.1.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (2022.9.24)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (3.2.1)\n",
      "Requirement already satisfied: test-tube in /home/bryan/venv/gpu/lib/python3.10/site-packages (0.7.5)\n",
      "Requirement already satisfied: future in /home/bryan/venv/gpu/lib/python3.10/site-packages (from test-tube) (0.18.2)\n",
      "Requirement already satisfied: torch>=1.1.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from test-tube) (1.13.0.dev20221005+cu117)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from test-tube) (2.22.1)\n",
      "Requirement already satisfied: pandas>=0.20.3 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from test-tube) (1.5.0)\n",
      "Requirement already satisfied: tensorboard>=1.15.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from test-tube) (2.10.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from test-tube) (1.23.3)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from imageio>=2.3.0->test-tube) (9.0.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from pandas>=0.20.3->test-tube) (2022.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from pandas>=0.20.3->test-tube) (2.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=1.15.0->test-tube) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=1.15.0->test-tube) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=1.15.0->test-tube) (2.12.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=1.15.0->test-tube) (2.2.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=1.15.0->test-tube) (0.37.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=1.15.0->test-tube) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=1.15.0->test-tube) (59.5.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=1.15.0->test-tube) (1.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=1.15.0->test-tube) (2.28.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=1.15.0->test-tube) (3.19.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=1.15.0->test-tube) (1.8.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from tensorboard>=1.15.0->test-tube) (1.49.1)\n",
      "Requirement already satisfied: typing-extensions in /home/bryan/venv/gpu/lib/python3.10/site-packages (from torch>=1.1.0->test-tube) (4.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15.0->test-tube) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard>=1.15.0->test-tube) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard>=1.15.0->test-tube) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard>=1.15.0->test-tube) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard>=1.15.0->test-tube) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard>=1.15.0->test-tube) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15.0->test-tube) (3.2.1)\n",
      "Requirement already satisfied: transformers in /home/bryan/venv/gpu/lib/python3.10/site-packages (4.22.2)\n",
      "Requirement already satisfied: filelock in /home/bryan/venv/gpu/lib/python3.10/site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from transformers) (1.23.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from transformers) (0.10.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in /home/bryan/venv/gpu/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from transformers) (2022.9.13)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: kornia in /home/bryan/venv/gpu/lib/python3.10/site-packages (0.6.7)\n",
      "Requirement already satisfied: packaging in /home/bryan/venv/gpu/lib/python3.10/site-packages (from kornia) (21.3)\n",
      "Requirement already satisfied: torch>=1.8.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from kornia) (1.13.0.dev20221005+cu117)\n",
      "Requirement already satisfied: typing-extensions in /home/bryan/venv/gpu/lib/python3.10/site-packages (from torch>=1.8.1->kornia) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from packaging->kornia) (3.0.9)\n",
      "Obtaining taming-transformers from git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
      "  Updating /home/bryan/venv/gpu/src/taming-transformers clone (to revision master)\n",
      "  Running command git fetch -q --tags\n",
      "  Running command git reset --hard -q 24268930bf1dce879235a7fddd0b2355b84d7ea6\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /home/bryan/venv/gpu/lib/python3.10/site-packages (from taming-transformers) (1.13.0.dev20221005+cu117)\n",
      "Requirement already satisfied: numpy in /home/bryan/venv/gpu/lib/python3.10/site-packages (from taming-transformers) (1.23.3)\n",
      "Requirement already satisfied: tqdm in /home/bryan/venv/gpu/lib/python3.10/site-packages (from taming-transformers) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions in /home/bryan/venv/gpu/lib/python3.10/site-packages (from torch->taming-transformers) (4.3.0)\n",
      "Installing collected packages: taming-transformers\n",
      "  Attempting uninstall: taming-transformers\n",
      "    Found existing installation: taming-transformers 0.0.1\n",
      "    Uninstalling taming-transformers-0.0.1:\n",
      "      Successfully uninstalled taming-transformers-0.0.1\n",
      "  Running setup.py develop for taming-transformers\n",
      "Successfully installed taming-transformers-0.0.1\n",
      "Obtaining clip from git+https://github.com/openai/CLIP.git@main#egg=clip\n",
      "  Updating /home/bryan/venv/gpu/src/clip clone (to revision main)\n",
      "  Running command git fetch -q --tags\n",
      "  Running command git reset --hard -q d50d76daa670286dd6cacf3bcd80b5e4823fc8e1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ftfy in /home/bryan/venv/gpu/lib/python3.10/site-packages (from clip) (6.1.1)\n",
      "Requirement already satisfied: regex in /home/bryan/venv/gpu/lib/python3.10/site-packages (from clip) (2022.9.13)\n",
      "Requirement already satisfied: tqdm in /home/bryan/venv/gpu/lib/python3.10/site-packages (from clip) (4.64.1)\n",
      "Requirement already satisfied: torch in /home/bryan/venv/gpu/lib/python3.10/site-packages (from clip) (1.13.0.dev20221005+cu117)\n",
      "Requirement already satisfied: torchvision in /home/bryan/venv/gpu/lib/python3.10/site-packages (from clip) (0.15.0.dev20221005+cu117)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ftfy->clip) (0.2.5)\n",
      "Requirement already satisfied: typing-extensions in /home/bryan/venv/gpu/lib/python3.10/site-packages (from torch->clip) (4.3.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/bryan/venv/gpu/lib/python3.10/site-packages (from torchvision->clip) (1.23.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from torchvision->clip) (9.0.1)\n",
      "Requirement already satisfied: requests in /home/bryan/venv/gpu/lib/python3.10/site-packages (from torchvision->clip) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests->torchvision->clip) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests->torchvision->clip) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests->torchvision->clip) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests->torchvision->clip) (2.1.1)\n",
      "Installing collected packages: clip\n",
      "  Attempting uninstall: clip\n",
      "    Found existing installation: clip 1.0\n",
      "    Uninstalling clip-1.0:\n",
      "      Successfully uninstalled clip-1.0\n",
      "  Running setup.py develop for clip\n",
      "Successfully installed clip-1.0\n",
      "Requirement already satisfied: setuptools==59.5.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (59.5.0)\n",
      "Requirement already satisfied: pillow==9.0.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (9.0.1)\n",
      "Requirement already satisfied: torchmetrics==0.6.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from torchmetrics==0.6.0) (1.23.3)\n",
      "Requirement already satisfied: packaging in /home/bryan/venv/gpu/lib/python3.10/site-packages (from torchmetrics==0.6.0) (21.3)\n",
      "Requirement already satisfied: torch>=1.3.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from torchmetrics==0.6.0) (1.13.0.dev20221005+cu117)\n",
      "Requirement already satisfied: typing-extensions in /home/bryan/venv/gpu/lib/python3.10/site-packages (from torch>=1.3.1->torchmetrics==0.6.0) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from packaging->torchmetrics==0.6.0) (3.0.9)\n",
      "Obtaining file:///home/bryan/Downloads/Dreambooth-Ion-Cannon\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /home/bryan/venv/gpu/lib/python3.10/site-packages (from latent-diffusion==0.0.1) (1.13.0.dev20221005+cu117)\n",
      "Requirement already satisfied: numpy in /home/bryan/venv/gpu/lib/python3.10/site-packages (from latent-diffusion==0.0.1) (1.23.3)\n",
      "Requirement already satisfied: tqdm in /home/bryan/venv/gpu/lib/python3.10/site-packages (from latent-diffusion==0.0.1) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions in /home/bryan/venv/gpu/lib/python3.10/site-packages (from torch->latent-diffusion==0.0.1) (4.3.0)\n",
      "Installing collected packages: latent-diffusion\n",
      "  Attempting uninstall: latent-diffusion\n",
      "    Found existing installation: latent-diffusion 0.0.1\n",
      "    Uninstalling latent-diffusion-0.0.1:\n",
      "      Successfully uninstalled latent-diffusion-0.0.1\n",
      "  Running setup.py develop for latent-diffusion\n",
      "Successfully installed latent-diffusion-0.0.1\n",
      "Collecting protobuf==3.20.1\n",
      "  Using cached protobuf-3.20.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorboard 2.10.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.1\n",
      "Requirement already satisfied: gdown in /home/bryan/venv/gpu/lib/python3.10/site-packages (4.5.1)\n",
      "Requirement already satisfied: requests[socks] in /home/bryan/venv/gpu/lib/python3.10/site-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: six in /home/bryan/venv/gpu/lib/python3.10/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /home/bryan/venv/gpu/lib/python3.10/site-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: filelock in /home/bryan/venv/gpu/lib/python3.10/site-packages (from gdown) (3.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests[socks]->gdown) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests[socks]->gdown) (2.1.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: pydrive in /home/bryan/venv/gpu/lib/python3.10/site-packages (1.3.1)\n",
      "Requirement already satisfied: oauth2client>=4.0.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from pydrive) (4.1.3)\n",
      "Requirement already satisfied: PyYAML>=3.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from pydrive) (6.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from pydrive) (2.64.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from google-api-python-client>=1.2->pydrive) (2.12.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from google-api-python-client>=1.2->pydrive) (0.20.4)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from google-api-python-client>=1.2->pydrive) (4.1.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from google-api-python-client>=1.2->pydrive) (2.10.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from google-api-python-client>=1.2->pydrive) (0.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from oauth2client>=4.0.0->pydrive) (0.4.8)\n",
      "Requirement already satisfied: six>=1.6.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from oauth2client>=4.0.0->pydrive) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from oauth2client>=4.0.0->pydrive) (0.2.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from oauth2client>=4.0.0->pydrive) (4.9)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->pydrive) (2.28.1)\n",
      "Requirement already satisfied: protobuf<5.0.0dev,>=3.20.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->pydrive) (3.20.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->pydrive) (1.56.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.2->pydrive) (5.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client>=1.2->pydrive) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->pydrive) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->pydrive) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->pydrive) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->pydrive) (2022.9.24)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-core 2.10.1 requires protobuf<5.0.0dev,>=3.20.1, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: huggingface_hub in /home/bryan/venv/gpu/lib/python3.10/site-packages (0.10.0)\n",
      "Requirement already satisfied: requests in /home/bryan/venv/gpu/lib/python3.10/site-packages (from huggingface_hub) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from huggingface_hub) (21.3)\n",
      "Requirement already satisfied: tqdm in /home/bryan/venv/gpu/lib/python3.10/site-packages (from huggingface_hub) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: filelock in /home/bryan/venv/gpu/lib/python3.10/site-packages (from huggingface_hub) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from huggingface_hub) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests->huggingface_hub) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests->huggingface_hub) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: ipywidgets==7.7.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (7.7.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipywidgets==7.7.1) (1.1.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipywidgets==7.7.1) (3.6.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipywidgets==7.7.1) (6.16.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipywidgets==7.7.1) (5.4.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipywidgets==7.7.1) (8.5.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipywidgets==7.7.1) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.1) (0.1.6)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.1) (24.0.1)\n",
      "Requirement already satisfied: packaging in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.1) (21.3)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.1) (6.2)\n",
      "Requirement already satisfied: debugpy>=1.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.1) (1.6.3)\n",
      "Requirement already satisfied: nest-asyncio in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.1) (1.5.6)\n",
      "Requirement already satisfied: psutil in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.1) (5.9.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.1) (7.3.5)\n",
      "Requirement already satisfied: pickleshare in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (0.7.5)\n",
      "Requirement already satisfied: backcall in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (0.2.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (2.13.0)\n",
      "Requirement already satisfied: decorator in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (5.1.1)\n",
      "Requirement already satisfied: stack-data in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (0.5.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (0.18.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (3.0.31)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (6.4.12)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets==7.7.1) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets==7.7.1) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in /home/bryan/venv/gpu/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets==7.7.1) (0.4)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets==7.7.1) (4.11.1)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in /home/bryan/venv/gpu/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.14.1)\n",
      "Requirement already satisfied: nbformat in /home/bryan/venv/gpu/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (5.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (3.1.2)\n",
      "Requirement already satisfied: nbconvert>=5 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (7.1.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.16.0)\n",
      "Requirement already satisfied: argon2-cffi in /home/bryan/venv/gpu/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (21.3.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets==7.7.1) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/bryan/venv/gpu/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython>=4.0.0->ipywidgets==7.7.1) (0.2.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from packaging->ipykernel>=4.5.1->ipywidgets==7.7.1) (3.0.9)\n",
      "Requirement already satisfied: executing in /home/bryan/venv/gpu/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets==7.7.1) (1.1.0)\n",
      "Requirement already satisfied: asttokens in /home/bryan/venv/gpu/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets==7.7.1) (2.0.8)\n",
      "Requirement already satisfied: pure-eval in /home/bryan/venv/gpu/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets==7.7.1) (0.2.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyterlab-pygments in /home/bryan/venv/gpu/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.2.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.6.8)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (1.5.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (4.11.1)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (2.1.1)\n",
      "Requirement already satisfied: defusedxml in /home/bryan/venv/gpu/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.7.1)\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (2.0.4)\n",
      "Requirement already satisfied: tinycss2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (1.1.1)\n",
      "Requirement already satisfied: bleach in /home/bryan/venv/gpu/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (5.0.1)\n",
      "Requirement already satisfied: fastjsonschema in /home/bryan/venv/gpu/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (4.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets==7.7.1) (1.16.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/bryan/venv/gpu/lib/python3.10/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (21.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.18.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in /home/bryan/venv/gpu/lib/python3.10/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.5.1)\n",
      "Requirement already satisfied: pycparser in /home/bryan/venv/gpu/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (2.21)\n",
      "Requirement already satisfied: py7zr==0.20.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (0.20.0)\n",
      "Requirement already satisfied: texttable in /home/bryan/venv/gpu/lib/python3.10/site-packages (from py7zr==0.20.0) (1.6.4)\n",
      "Requirement already satisfied: brotli>=1.0.9 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from py7zr==0.20.0) (1.0.9)\n",
      "Requirement already satisfied: pybcj>=0.6.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from py7zr==0.20.0) (1.0.1)\n",
      "Requirement already satisfied: inflate64>=0.3.0 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from py7zr==0.20.0) (0.3.0)\n",
      "Requirement already satisfied: psutil in /home/bryan/venv/gpu/lib/python3.10/site-packages (from py7zr==0.20.0) (5.9.2)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from py7zr==0.20.0) (0.2.3)\n",
      "Requirement already satisfied: pyppmd<0.19.0,>=0.18.1 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from py7zr==0.20.0) (0.18.3)\n",
      "Requirement already satisfied: pyzstd>=0.14.4 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from py7zr==0.20.0) (0.15.3)\n",
      "Requirement already satisfied: pycryptodomex>=3.6.6 in /home/bryan/venv/gpu/lib/python3.10/site-packages (from py7zr==0.20.0) (3.15.0)\n",
      "Requirement already satisfied: multivolumefile in /home/bryan/venv/gpu/lib/python3.10/site-packages (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "#BUILD ENV\n",
    "!pip install omegaconf\n",
    "!pip install einops\n",
    "!pip install pytorch-lightning==1.6.5\n",
    "!pip install test-tube\n",
    "!pip install transformers\n",
    "!pip install kornia\n",
    "!pip install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
    "!pip install -e git+https://github.com/openai/CLIP.git@main#egg=clip\n",
    "!pip install setuptools==59.5.0\n",
    "!pip install pillow==9.0.1\n",
    "!pip install torchmetrics==0.6.0\n",
    "!pip install -e .\n",
    "!pip install protobuf==3.20.1\n",
    "!pip install gdown\n",
    "!pip install pydrive\n",
    "!pip install -qq diffusers[\"training\"]==0.3.0 transformers ftfy\n",
    "!pip install -qq \"ipywidgets>=7,<8\"\n",
    "!pip install huggingface_hub\n",
    "!pip install ipywidgets==7.7.1\n",
    "!pip install py7zr==0.20.0\n",
    "!pip install multivolumefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df41bd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_PATH=\".\"\n",
    "# REPO_PATH=\"/workspace/Dreambooth-Ion-Cannon\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32304cfd",
   "metadata": {},
   "source": [
    "# Decompressing/Reconstituting Stable Diffusion v1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dae11c10",
   "metadata": {
    "id": "dae11c10"
   },
   "outputs": [],
   "source": [
    "import multivolumefile\n",
    "import py7zr\n",
    "with multivolumefile.open('base_model/model.7z', mode='rb') as target_archive:\n",
    "    with py7zr.SevenZipFile(target_archive, 'r') as archive:\n",
    "        archive.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4e50df",
   "metadata": {
    "id": "ad4e50df"
   },
   "source": [
    "# Training and Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c16c29d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_token = f\"{target_name} {target_class}\"\n",
    "project_name = f\"{target_name}_model\"\n",
    "model_name = f\"{project_name}.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45901b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/stable_txt2img.py \\\n",
    " --ddim_eta 0.0 \\\n",
    " --n_samples 8 \\\n",
    " --n_iter 8 \\\n",
    " --seed 2148934030 \\\n",
    " --scale 10.0 \\\n",
    " --ddim_steps 100 \\\n",
    " --ckpt {model_path} \\\n",
    " --prompt \"{target_token}, portrait shinkai makoto studio ghibli studio key hideaki anno sakimichan stanley artgerm lau rossdraws james jean marc simonetti elegant highly detailed digital painting artstation pixiv\" \\\n",
    " --outloc \"{target_name}_ghibli\" \\\n",
    " --outdir \"outputs/{target_name}_ghibli\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43463865",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/stable_txt2img.py \\\n",
    " --ddim_eta 0.0 \\\n",
    " --n_samples 8 \\\n",
    " --n_iter 8 \\\n",
    " --seed 1694397999 \\\n",
    " --scale 10.0 \\\n",
    " --ddim_steps 100 \\\n",
    " --ckpt {model_path} \\\n",
    " --prompt \"a beautiful portrait of {target_token}, with isolated flowers with strong dark comic outlines, colorful, psychedelic, intricate, elegant, highly detailed, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha\" \\\n",
    " --outloc \"{target_name}_flowers\" \\\n",
    " --outdir \"outputs/{target_name}_flowers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3d3e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/stable_txt2img.py \\\n",
    " --ddim_eta 0.0 \\\n",
    " --n_samples 8 \\\n",
    " --n_iter 8 \\\n",
    " --seed 1337 \\\n",
    " --scale 10.0 \\\n",
    " --ddim_steps 100 \\\n",
    " --ckpt {model_path} \\\n",
    " --prompt \"digital painting of {target_token} cosmic background, scenery landscape, professional, award - winning, trending on artstation, hyper detailed, realistic, beautiful, emotional, shiny, golden, picture\" \\\n",
    " --outloc \"{target_name}_cosmic\" \\\n",
    " --outdir \"outputs/{target_name}_cosmic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2073373",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/stable_txt2img.py \\\n",
    " --ddim_eta 0.0 \\\n",
    " --n_samples 8 \\\n",
    " --n_iter 8 \\\n",
    " --seed 69 \\\n",
    " --scale 10.0 \\\n",
    " --ddim_steps 100 \\\n",
    " --ckpt {model_path} \\\n",
    " --prompt \"portrait of {target_token} cyberpunk neon - bordered cyborg, 7 0 mm focal length, by ilya kuvshinov, krenz cushart, Greg Rutkowski, trending on artstation sharp focus illustration, aesthetic, very inspirational, arthouse\" \\\n",
    " --outloc \"{target_name}_cyborg\" \\\n",
    " --outdir \"outputs/{target_name}_cyborg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedc1b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/stable_txt2img.py \\\n",
    " --ddim_eta 0.0 \\\n",
    " --n_samples 8 \\\n",
    " --n_iter 8 \\\n",
    " --seed 3491584590 \\\n",
    " --scale 10.0 \\\n",
    " --ddim_steps 100 \\\n",
    " --ckpt {model_path} \\\n",
    " --prompt \"bioshock {target_token} as big sister portrait, intricate, elegant, highly detailed, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha\" \\\n",
    " --outloc \"{target_name}_bioshock\" \\\n",
    " --outdir \"outputs/{target_name}_bioshock\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9c0e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/stable_txt2img.py \\\n",
    " --ddim_eta 0.0 \\\n",
    " --n_samples 8 \\\n",
    " --n_iter 8 \\\n",
    " --seed 1201562208 \\\n",
    " --scale 10.0 \\\n",
    " --ddim_steps 100 \\\n",
    " --ckpt {model_path} \\\n",
    " --prompt \"A soft and breathtaking detailed painting of a {target_token} with a crown on their head in the style of gustav klimt, shiny gold, elegant, highly detailed, artstation, fluo colors, concept art, matte, sharp focus, art by gustav klimt and alphonse mucha\" \\\n",
    " --outloc \"{target_name}_crown\" \\\n",
    " --outdir \"outputs/{target_name}_crown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91479a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/stable_txt2img.py \\\n",
    " --ddim_eta 0.0 \\\n",
    " --n_samples 8 \\\n",
    " --n_iter 8 \\\n",
    " --seed 69 \\\n",
    " --scale 10.0 \\\n",
    " --ddim_steps 100 \\\n",
    " --ckpt {model_path} \\\n",
    " --prompt \"digital painting of {target_token} by greg rutkowski neon cyberpunk\" \\\n",
    " --outloc \"{target_name}_cyberpunk\" \\\n",
    " --outdir \"outputs/{target_name}_cyberpunk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee5a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/stable_txt2img.py \\\n",
    " --ddim_eta 0.0 \\\n",
    " --n_samples 8 \\\n",
    " --n_iter 8 \\\n",
    " --seed 4085433209 \\\n",
    " --scale 10.0 \\\n",
    " --ddim_steps 100 \\\n",
    " --ckpt {model_path} \\\n",
    " --prompt \"Up close portrait of a beautiful {target_token} in black and white, photorealistic, upper body, art by diego fazio and diegokoi and artgerm, concept art, hyper sharp focus, 8k highly detailed\" \\\n",
    " --outloc \"{target_name}_blackwhite\" \\\n",
    " --outdir \"outputs/{target_name}_blackwhite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5358a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/stable_txt2img.py \\\n",
    " --ddim_eta 0.0 \\\n",
    " --n_samples 8 \\\n",
    " --n_iter 8 \\\n",
    " --seed 2603348708 \\\n",
    " --scale 10.0 \\\n",
    " --ddim_steps 100 \\\n",
    " --ckpt {model_path} \\\n",
    " --prompt \"A beautiful portrait of a {target_token} with diamonds and glittering skin, a detailed painting by greg rutkowski and raymond swanland, featured on cgsociety, fantasy art, detailed painting, artstation hd, photorealistic, fantasy, intricate, elegant, rainbow bubbles, highly detailed, digital painting\" \\\n",
    " --outloc \"{target_name}_ethereal\" \\\n",
    " --outdir \"outputs/{target_name}_ethereal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a505e5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/stable_txt2img.py \\\n",
    " --ddim_eta 0.0 \\\n",
    " --n_samples 2 \\\n",
    " --n_iter 2 \\\n",
    " --seed 42 \\\n",
    " --scale 10.0 \\\n",
    " --ddim_steps 100 \\\n",
    " --ckpt {model_path} \\\n",
    " --prompt \"{target_token}\" \\\n",
    " --outloc \"{target_name}_raw\" \\\n",
    " --outdir \"outputs/{target_name}_raw\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28d0139",
   "metadata": {},
   "source": [
    "# Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91aa9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"/workspace/Dreambooth-Ion-Cannon/trained_models/{model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce59d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint_file_pruned = directory_paths[-1] + \"/checkpoints/last-pruned.ckpt\"\n",
    "!mkdir -p trained_models\n",
    "!mv {last_checkpoint_file_pruned} trained_models/{model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9e86e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This version should automatically prune around 10GB from the ckpt file\n",
    "last_checkpoint_file = directory_paths[-1] + \"/checkpoints/last.ckpt\"\n",
    "!python \"prune_ckpt.py\" --ckpt {last_checkpoint_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f8e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_paths = !ls -d logs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fbf17aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrissy_model.ckpt\r\n"
     ]
    }
   ],
   "source": [
    "!echo {model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e500af24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTORCH_ENABLE_MPS_FALLBACK=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa5dd66-2ca0-4819-907e-802e25583ae6",
   "metadata": {
    "id": "6fa5dd66-2ca0-4819-907e-802e25583ae6",
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 23\n",
      "Running on GPUs 0,\n",
      "Loading model from model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 859.52 M params.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 64, 64) = 16384 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.14.self_attn.q_proj.bias', 'visual_projection.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.11.layer_norm1.bias', 'text_projection.weight', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'logit_scale', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.bias']\n",
      "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored from model.ckpt with 0 missing and 2 unexpected keys\n",
      "Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']\n",
      "/home/bryan/venv/gpu/lib/python3.10/site-packages/pytorch_lightning/loggers/test_tube.py:105: LightningDeprecationWarning: The TestTubeLogger is deprecated since v1.5 and will be removed in v1.7. We recommend switching to the `pytorch_lightning.loggers.TensorBoardLogger` as an alternative.\n",
      "  rank_zero_deprecation(\n",
      "Monitoring val/loss_simple_ema as checkpoint metric.\n",
      "Merged modelckpt-cfg: \n",
      "{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/training_samples2022-10-05T23-02-23_chrissy_model/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/loss_simple_ema', 'save_top_k': 1, 'every_n_train_steps': 500}}\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "#### Data #####\n",
      "train, PersonalizedBatchBase, 1000\n",
      "validation, PersonalizedBase, 10\n",
      "accumulate_grad_batches = 1\n",
      "++++ NOT USING LR SCALING ++++\n",
      "Setting learning rate to 1.00e-06\n",
      "#### START FITTING\n",
      "/home/bryan/venv/gpu/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:326: LightningDeprecationWarning: Base `LightningModule.on_train_batch_start` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "/home/bryan/venv/gpu/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/bryan/venv/gpu/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_start` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/bryan/venv/gpu/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:342: LightningDeprecationWarning: Base `Callback.on_train_batch_end` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LatentDiffusion: Also optimizing conditioner params!\n",
      "\n",
      "  | Name              | Type               | Params\n",
      "---------------------------------------------------------\n",
      "0 | model             | DiffusionWrapper   | 859 M \n",
      "1 | first_stage_model | AutoencoderKL      | 83.7 M\n",
      "2 | cond_stage_model  | FrozenCLIPEmbedder | 123 M \n",
      "---------------------------------------------------------\n",
      "982 M     Trainable params\n",
      "83.7 M    Non-trainable params\n",
      "1.1 B     Total params\n",
      "4,264.941 Total estimated model params size (MB)\n",
      "Project config\n",
      "model:\n",
      "  base_learning_rate: 1.0e-06\n",
      "  target: ldm.models.diffusion.ddpm.LatentDiffusion\n",
      "  params:\n",
      "    reg_weight: 1.0\n",
      "    linear_start: 0.00085\n",
      "    linear_end: 0.012\n",
      "    num_timesteps_cond: 1\n",
      "    log_every_t: 200\n",
      "    timesteps: 1000\n",
      "    first_stage_key: image\n",
      "    cond_stage_key: caption\n",
      "    image_size: 64\n",
      "    channels: 4\n",
      "    cond_stage_trainable: true\n",
      "    conditioning_key: crossattn\n",
      "    monitor: val/loss_simple_ema\n",
      "    scale_factor: 0.18215\n",
      "    use_ema: false\n",
      "    embedding_reg_weight: 0.0\n",
      "    unfreeze_model: true\n",
      "    model_lr: 1.0e-06\n",
      "    personalization_config:\n",
      "      target: ldm.modules.embedding_manager.EmbeddingManager\n",
      "      params:\n",
      "        placeholder_strings:\n",
      "        - '*'\n",
      "        initializer_words:\n",
      "        - sculpture\n",
      "        per_image_tokens: false\n",
      "        num_vectors_per_token: 1\n",
      "        progressive_words: false\n",
      "    unet_config:\n",
      "      target: ldm.modules.diffusionmodules.openaimodel.UNetModel\n",
      "      params:\n",
      "        image_size: 32\n",
      "        in_channels: 4\n",
      "        out_channels: 4\n",
      "        model_channels: 320\n",
      "        attention_resolutions:\n",
      "        - 4\n",
      "        - 2\n",
      "        - 1\n",
      "        num_res_blocks: 2\n",
      "        channel_mult:\n",
      "        - 1\n",
      "        - 2\n",
      "        - 4\n",
      "        - 4\n",
      "        num_heads: 8\n",
      "        use_spatial_transformer: true\n",
      "        transformer_depth: 1\n",
      "        context_dim: 768\n",
      "        use_checkpoint: true\n",
      "        legacy: false\n",
      "    first_stage_config:\n",
      "      target: ldm.models.autoencoder.AutoencoderKL\n",
      "      params:\n",
      "        embed_dim: 4\n",
      "        monitor: val/rec_loss\n",
      "        ddconfig:\n",
      "          double_z: true\n",
      "          z_channels: 4\n",
      "          resolution: 512\n",
      "          in_channels: 3\n",
      "          out_ch: 3\n",
      "          ch: 128\n",
      "          ch_mult:\n",
      "          - 1\n",
      "          - 2\n",
      "          - 4\n",
      "          - 4\n",
      "          num_res_blocks: 2\n",
      "          attn_resolutions: []\n",
      "          dropout: 0.0\n",
      "        lossconfig:\n",
      "          target: torch.nn.Identity\n",
      "    cond_stage_config:\n",
      "      target: ldm.modules.encoders.modules.FrozenCLIPEmbedder\n",
      "    ckpt_path: model.ckpt\n",
      "data:\n",
      "  target: main.DataModuleFromConfig\n",
      "  params:\n",
      "    batch_size: 1\n",
      "    num_workers: 1\n",
      "    wrap: false\n",
      "    train:\n",
      "      target: ldm.data.personalized_batch.PersonalizedBatchBase\n",
      "      params:\n",
      "        size: 512\n",
      "        set: train\n",
      "        repeats: 100\n",
      "    validation:\n",
      "      target: ldm.data.personalized.PersonalizedBase\n",
      "      params:\n",
      "        size: 512\n",
      "        set: val\n",
      "        repeats: 10\n",
      "\n",
      "Lightning config\n",
      "modelcheckpoint:\n",
      "  params:\n",
      "    every_n_train_steps: 500\n",
      "callbacks:\n",
      "  image_logger:\n",
      "    target: main.ImageLogger\n",
      "    params:\n",
      "      batch_frequency: 500\n",
      "      max_images: 8\n",
      "      increase_log_steps: false\n",
      "trainer:\n",
      "  benchmark: true\n",
      "  max_steps: 1000\n",
      "  gpus: 0,\n",
      "\n",
      "Sanity Checking: 0it [00:00, ?it/s]/home/bryan/venv/gpu/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/bryan/venv/gpu/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Training: 0it [00:00, ?it/s]/home/bryan/venv/gpu/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:2102: LightningDeprecationWarning: `Trainer.root_gpu` is deprecated in v1.6 and will be removed in v1.8. Please use `Trainer.strategy.root_device.index` instead.\n",
      "  rank_zero_deprecation(\n",
      "Epoch 0:   0%|                                         | 0/1010 [00:00<?, ?it/s]/home/bryan/venv/gpu/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/home/bryan/venv/gpu/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:229: UserWarning: You called `self.log('global_step', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "Epoch 0:  19%|▏| 190/1010 [03:56<17:00,  1.24s/it, loss=0.266, v_num=0, train/lo"
     ]
    }
   ],
   "source": [
    "!rm -rf training_samples/{target_class}/.ipynb_checkpoints\n",
    "!python \"main.py\" \\\n",
    " --base configs/stable-diffusion/v1-finetune_unfrozen.yaml \\\n",
    " -t \\\n",
    " --actual_resume \"model.ckpt\" \\\n",
    " --reg_data_root \"{REPO_PATH}/outputs/txt2img-samples/regularization\" \\\n",
    " -n {project_name} \\\n",
    " --gpus 0, \\\n",
    " --data_root \"{REPO_PATH}/training_samples\" \\\n",
    " --max_training_steps 1000 \\\n",
    " --no-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6ae3a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\r\n",
      "Version: 1.12.1\r\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\r\n",
      "Home-page: https://pytorch.org/\r\n",
      "Author: PyTorch Team\r\n",
      "Author-email: packages@pytorch.org\r\n",
      "License: BSD-3\r\n",
      "Location: /home/bryan/venv/gpu/lib/python3.10/site-packages\r\n",
      "Requires: typing-extensions\r\n",
      "Required-by: accelerate, clip, diffusers, kornia, latent-diffusion, pytorch-lightning, taming-transformers, test-tube, torchmetrics, torchvision\r\n"
     ]
    }
   ],
   "source": [
    "!pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab21bf73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
